{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report - Classifying Business Status\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Problem\n",
    "Starting and running a successful business is a fulfilling yet incredibly challenging endeavor. According to the U.S. Bureau of Labor Statistics (BLS), roughly 45% of businesses fail within the first 5 years after its inception. Businesses fail due to various reasons; for instance, lack of market knowledge, bad location, little financing, bad service, and etc. With that being said, I decided to create a classification model that predicts whether the restaurant will close or remain open with given information (revenue, lifespan, review ratings, etc.). \n",
    "\n",
    "### 1.2 Target Audience\n",
    "The model will be useful for financial lenders and investors in determining whether to lend/invest in restaurant business and it also provides aspiring restaurateurs whether their particular restaurant concept will be successful or not. Overall, the model helps minimize financial loss for all involved parties.\n",
    "\n",
    "### 1.3 Dataset\n",
    "I am using [Yelp's dataset](https://www.yelp.com/dataset) which was retrieved in July, 2020. The dataset consists of 10 metropolitan areas which ahs the following information:\n",
    "- 8,021,122 reviews\n",
    "- 209,393 businesses\n",
    "- 200,000 pictures\n",
    "- 1,320,71 tips\n",
    "- 1,968,703 users\n",
    "- Over 1.4 million business attributes.\n",
    "\n",
    "<img src=\"img/dataset_img.png\" alt=\"business\" style=\"width: 100%;\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Wrangling\n",
    "Prior to data wrangling, I utilized [json_to_csv.py](https://github.com/Yelp/dataset-examples/blob/master/json_to_csv_converter.py) to flatten nested json objects within a business' attributes column which has created additional 40 columns that have ‘attributes’ as its prefix. For example, attributes.Caters, attributes.RestaurantsAttire, etc.\n",
    "\n",
    "The scope of this project is geared towards ‘independent’ restaurants in hospitality industry, therefore, businesses dataset needed to be cleaned and transformed. Below are the following data cleaning summaries per dataset.\n",
    "\n",
    "### 2.1 Business Dataset\n",
    "The business dataframe contained 209393 businesses mainly from hospitality industry (restaurants, bars, food, etc.), however there were significant number of businesses that were part of chain restaurants/businesses and businesses that were not food/drinks related (law firms, pet grooming, real estate, etc.); therefore, those were needed to be filtered out.\n",
    "- Removed 52954 businesses that were part of chain restaurants which cut reduced to 143,958 (38% reduction)\n",
    "- Removed non-food/drinks related businesses reducing from 143,958 to 44,046 businesses (69.4% reduction)\n",
    "\n",
    "##### Handling NaNs in Business Dataframe\n",
    "There were multiple columns related to businesses' attributes such as goodforkids, goodforgroups, tableservice, delivery, etc. that had NaNs - as it was not explicitly defined on initial dataset - I had set to 0 as if it did  not offer those services.\n",
    "\n",
    "Missing price value within price column (16%) is replaced by rounded average price from most similar businesses between (1-4). \n",
    "\n",
    "###### Summary of Business Dataset\n",
    "1. Filtered business dataset to only populate hospitality related businesses (restaurants, clubs, bars, etc.).\n",
    "2. Removed businesses that were missing both attributes and categories values as those will be essential for feature engineering.\n",
    "3. Removed multi-unit restaurants such as chain restaurants as this project is concerned with single-unit businesses.\n",
    "4. Used categories and attributes data to identify restaurants' characteristics and what type of food/cuisine they are serving.\n",
    "5. Used cosine similarity amongst businesses to fill in missing price range.\n",
    "6. Removed columns that were not needed such as address, city, state, and etc.\n",
    "7. Increase column size from 60 to 144 columns\n",
    "8. Adjusted average star rating to have better representation at the same scale. For instance, one restaurant with 5 stars rating with 2 reviews is not same as other restaurant with 3.5 stars with 100+ reviews.\n",
    "8. Reduced business dataset from 209,393 to 44,046 rows.\n",
    "\n",
    "### 2.2 Review Dataset\n",
    "The review dataframe contains 8,021,122 entries \n",
    "- Removed 4,750,990 reviews that were part of businessses in filtered business dataframe\n",
    "- Converted text column from object to string datatype\n",
    "\n",
    "###### Summary of Review Dataset\n",
    "1. Reduced business dataset from 8,021,121 to 3,270,132 rows (59% reduction); using filered business dataframe's business_id column.\n",
    "2. No NaNs found\n",
    "3. Added two new columns:\n",
    "    - review_type: defines whether review is positive or negative in binary value based on user's average star rating.\n",
    "    - text_count: total text count per review\n",
    "\n",
    "### 2.3 User and Tip Dataset\n",
    "The user dataframe contains 1,968,703 entries which reviewed businesses spanning across 10 metropolitan areas. For this classification project, user dataframe is not needed as the column values provided does not bring any value in predicting whether restaurant will close or not. User dataframe is used to filter tips dataframe using filtered user dataframe (removed users that was not in filtered review dataframe.)\n",
    "\n",
    "Unlike review dataframe, tips does not have any quantifiable values to determine whether it is a good comment or not for the restaurants. Therefore, sentiment analysis was used to define each tip as positive (1) or negative (0) based on its compound score.\n",
    "\n",
    "**Note**\n",
    "\n",
    "The Compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "\n",
    "- positive sentiment : (compound score >= 0.05)\n",
    "- neutral sentiment : (compound score > -0.05) and (compound score < 0.05)\n",
    "- negative sentiment : (compound score <= -0.05)\n",
    "\n",
    "##### Summary of Tip Dataset\n",
    "1. Converted tip's text column datatype to string.\n",
    "1. Filtered tip dataset using updated user dataset's user_id.\n",
    "2. Removed all columns except user_id, text, date, and sentiment analysis related columns.\n",
    "2. Reduced tip dataset from 1,320,761 to 1,136,880 rows. (14% reduction)\n",
    "3. Removed two rows that had null values.\n",
    "\n",
    "### 2.4 Check-In Dataset\n",
    "The checkin dataframe contains 175,187 entries which is the least amount of entries compared to aforementioned datasets. \n",
    "\n",
    "##### Summary of Check-In Dataset\n",
    "1. Filtered checkin dataset using filtered review dataframe\n",
    "2. Reduced checkin dataset from 175,187 to 42,296 rows.\n",
    "3. No null values were found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
